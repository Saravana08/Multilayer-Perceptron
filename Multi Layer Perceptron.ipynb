{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Pereceptron Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "\n",
    "# create mutli-layer perceptron classifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "# train\n",
    "clf.fit(X, y)\n",
    "\n",
    "# make predictions\n",
    "print( clf.predict([[2., 2.]]) )\n",
    "print( clf.predict([[0, -1]]) )\n",
    "print( clf.predict([[1, 2]]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print( clf.predict([[1, 3]]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Pereceptron Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first neural network with keras tutorial\n",
    "from numpy import loadtxt\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laoading the dataset\n",
    "data= loadtxt(r'C:\\Users\\saravana.ayyappa\\Desktop\\Intro-to-Machine-Learning-master\\Multi Layer perceptron - Keras\\pima-indians-diabetes.data.txt',delimiter=',')\n",
    "\n",
    "X = data[:,0:8]\n",
    "y = data[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 768 samples\n",
      "Epoch 1/150\n",
      "768/768 [==============================] - 1s 827us/sample - loss: 1.7571 - accuracy: 0.5521\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 144us/sample - loss: 1.0494 - accuracy: 0.5872\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 156us/sample - loss: 0.8090 - accuracy: 0.6094\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 129us/sample - loss: 0.6979 - accuracy: 0.6328\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 157us/sample - loss: 0.6818 - accuracy: 0.6458\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 119us/sample - loss: 0.6672 - accuracy: 0.6536\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 148us/sample - loss: 0.6363 - accuracy: 0.6706\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 154us/sample - loss: 0.6314 - accuracy: 0.6615\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 140us/sample - loss: 0.6274 - accuracy: 0.6719\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 140us/sample - loss: 0.6224 - accuracy: 0.6758\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 131us/sample - loss: 0.6323 - accuracy: 0.6458\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 126us/sample - loss: 0.6281 - accuracy: 0.6745\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 154us/sample - loss: 0.6063 - accuracy: 0.6914\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 171us/sample - loss: 0.5943 - accuracy: 0.6888\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 134us/sample - loss: 0.5938 - accuracy: 0.6992\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 149us/sample - loss: 0.5935 - accuracy: 0.7096\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 126us/sample - loss: 0.5906 - accuracy: 0.6914\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 144us/sample - loss: 0.5831 - accuracy: 0.7122\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 122us/sample - loss: 0.5820 - accuracy: 0.7018\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 150us/sample - loss: 0.5764 - accuracy: 0.7031\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 131us/sample - loss: 0.5763 - accuracy: 0.7161\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 154us/sample - loss: 0.5995 - accuracy: 0.6901\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 129us/sample - loss: 0.5716 - accuracy: 0.7188\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 121us/sample - loss: 0.5784 - accuracy: 0.7109\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 183us/sample - loss: 0.5939 - accuracy: 0.6836\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 177us/sample - loss: 0.5650 - accuracy: 0.7122\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 170us/sample - loss: 0.5742 - accuracy: 0.7279\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 191us/sample - loss: 0.5744 - accuracy: 0.7188\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 191us/sample - loss: 0.5613 - accuracy: 0.7240\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 154us/sample - loss: 0.5624 - accuracy: 0.7135\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 181us/sample - loss: 0.5754 - accuracy: 0.7031\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 180us/sample - loss: 0.5642 - accuracy: 0.7122\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 196us/sample - loss: 0.5627 - accuracy: 0.7070\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 193us/sample - loss: 0.5446 - accuracy: 0.7201\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 210us/sample - loss: 0.5476 - accuracy: 0.7344\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 169us/sample - loss: 0.5536 - accuracy: 0.7266\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 201us/sample - loss: 0.5456 - accuracy: 0.7188\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 187us/sample - loss: 0.5347 - accuracy: 0.7370\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 165us/sample - loss: 0.5455 - accuracy: 0.7188\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 151us/sample - loss: 0.5559 - accuracy: 0.7331\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 189us/sample - loss: 0.5517 - accuracy: 0.7148\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 176us/sample - loss: 0.5291 - accuracy: 0.7396\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 167us/sample - loss: 0.5350 - accuracy: 0.7279\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 166us/sample - loss: 0.5402 - accuracy: 0.7279\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 140us/sample - loss: 0.5307 - accuracy: 0.7201\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 155us/sample - loss: 0.5490 - accuracy: 0.7279\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 171us/sample - loss: 0.5492 - accuracy: 0.7266\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 154us/sample - loss: 0.5322 - accuracy: 0.7331\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 147us/sample - loss: 0.5323 - accuracy: 0.7318\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 136us/sample - loss: 0.5295 - accuracy: 0.7253\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 134us/sample - loss: 0.5282 - accuracy: 0.7357\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 156us/sample - loss: 0.5262 - accuracy: 0.7500\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 168us/sample - loss: 0.5254 - accuracy: 0.7500\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 153us/sample - loss: 0.5217 - accuracy: 0.7344\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 139us/sample - loss: 0.5199 - accuracy: 0.7409\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 145us/sample - loss: 0.5232 - accuracy: 0.7292\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 158us/sample - loss: 0.5224 - accuracy: 0.7305\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 149us/sample - loss: 0.5129 - accuracy: 0.7500\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 164us/sample - loss: 0.5140 - accuracy: 0.7617\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 157us/sample - loss: 0.5164 - accuracy: 0.7448\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 140us/sample - loss: 0.5258 - accuracy: 0.7396\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 128us/sample - loss: 0.5214 - accuracy: 0.7435\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 120us/sample - loss: 0.5218 - accuracy: 0.7474\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 152us/sample - loss: 0.5168 - accuracy: 0.7448\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 165us/sample - loss: 0.5264 - accuracy: 0.7435\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 140us/sample - loss: 0.5117 - accuracy: 0.7526\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 146us/sample - loss: 0.5273 - accuracy: 0.7500\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 139us/sample - loss: 0.5221 - accuracy: 0.7331\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 115us/sample - loss: 0.5059 - accuracy: 0.7500\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 169us/sample - loss: 0.5209 - accuracy: 0.7526\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 132us/sample - loss: 0.5277 - accuracy: 0.7344\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 136us/sample - loss: 0.5100 - accuracy: 0.7487\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 170us/sample - loss: 0.5053 - accuracy: 0.7526\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 143us/sample - loss: 0.5025 - accuracy: 0.7643\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 181us/sample - loss: 0.5046 - accuracy: 0.7526\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 155us/sample - loss: 0.4949 - accuracy: 0.7539\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 160us/sample - loss: 0.5039 - accuracy: 0.7500\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 145us/sample - loss: 0.5111 - accuracy: 0.7370\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 120us/sample - loss: 0.5080 - accuracy: 0.7487\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 151us/sample - loss: 0.5030 - accuracy: 0.7474\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 186us/sample - loss: 0.5021 - accuracy: 0.7604\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 157us/sample - loss: 0.5107 - accuracy: 0.7422\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s 116us/sample - loss: 0.4944 - accuracy: 0.7591\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 136us/sample - loss: 0.4958 - accuracy: 0.7487\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 129us/sample - loss: 0.4960 - accuracy: 0.7617\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 160us/sample - loss: 0.4967 - accuracy: 0.7578\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 123us/sample - loss: 0.4962 - accuracy: 0.7604\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 145us/sample - loss: 0.5047 - accuracy: 0.7422\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 139us/sample - loss: 0.4961 - accuracy: 0.7565\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 109us/sample - loss: 0.4912 - accuracy: 0.7565\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 115us/sample - loss: 0.4910 - accuracy: 0.7591\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 137us/sample - loss: 0.5015 - accuracy: 0.7604\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 158us/sample - loss: 0.4983 - accuracy: 0.7513\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 131us/sample - loss: 0.4890 - accuracy: 0.7643\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 129us/sample - loss: 0.4899 - accuracy: 0.7513\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 131us/sample - loss: 0.4964 - accuracy: 0.7708\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 131us/sample - loss: 0.4976 - accuracy: 0.7656\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 127us/sample - loss: 0.4888 - accuracy: 0.7552\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 128us/sample - loss: 0.4946 - accuracy: 0.7643\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 205us/sample - loss: 0.4913 - accuracy: 0.7695\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 190us/sample - loss: 0.4999 - accuracy: 0.7591\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 189us/sample - loss: 0.4927 - accuracy: 0.7617\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 174us/sample - loss: 0.4781 - accuracy: 0.7682\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 223us/sample - loss: 0.4839 - accuracy: 0.7643\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 183us/sample - loss: 0.4812 - accuracy: 0.7734\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 177us/sample - loss: 0.4831 - accuracy: 0.7591\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 146us/sample - loss: 0.4855 - accuracy: 0.7578\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 170us/sample - loss: 0.4824 - accuracy: 0.7565\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 174us/sample - loss: 0.4861 - accuracy: 0.7669\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 151us/sample - loss: 0.4977 - accuracy: 0.7630\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 150us/sample - loss: 0.4798 - accuracy: 0.7708\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 191us/sample - loss: 0.4896 - accuracy: 0.7643\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 182us/sample - loss: 0.4876 - accuracy: 0.7474\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 169us/sample - loss: 0.4781 - accuracy: 0.7760\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 182us/sample - loss: 0.4887 - accuracy: 0.7682\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 162us/sample - loss: 0.4778 - accuracy: 0.7669\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 192us/sample - loss: 0.4775 - accuracy: 0.7734\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 189us/sample - loss: 0.4802 - accuracy: 0.7630\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 183us/sample - loss: 0.4806 - accuracy: 0.7591\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 174us/sample - loss: 0.4756 - accuracy: 0.7669\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 171us/sample - loss: 0.4768 - accuracy: 0.7734\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 169us/sample - loss: 0.4775 - accuracy: 0.7734\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 163us/sample - loss: 0.4797 - accuracy: 0.7708\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 179us/sample - loss: 0.4726 - accuracy: 0.7565\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 135us/sample - loss: 0.4793 - accuracy: 0.7656\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 121us/sample - loss: 0.4870 - accuracy: 0.7682\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 141us/sample - loss: 0.4925 - accuracy: 0.7526\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 160us/sample - loss: 0.4790 - accuracy: 0.7695\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 157us/sample - loss: 0.4740 - accuracy: 0.7773\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 171us/sample - loss: 0.4762 - accuracy: 0.7695\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 130us/sample - loss: 0.4644 - accuracy: 0.7747\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 143us/sample - loss: 0.4740 - accuracy: 0.7513\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 151us/sample - loss: 0.4849 - accuracy: 0.7552\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 138us/sample - loss: 0.4696 - accuracy: 0.7669\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 176us/sample - loss: 0.4658 - accuracy: 0.7669\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 158us/sample - loss: 0.4699 - accuracy: 0.7904\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 151us/sample - loss: 0.4664 - accuracy: 0.7760\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 139us/sample - loss: 0.4720 - accuracy: 0.7604\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 141us/sample - loss: 0.4621 - accuracy: 0.7826\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 119us/sample - loss: 0.4737 - accuracy: 0.7786\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 137us/sample - loss: 0.4600 - accuracy: 0.7708\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 160us/sample - loss: 0.4644 - accuracy: 0.7812\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 142us/sample - loss: 0.4732 - accuracy: 0.7643\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 153us/sample - loss: 0.4750 - accuracy: 0.7656\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 135us/sample - loss: 0.4756 - accuracy: 0.7773\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 157us/sample - loss: 0.4666 - accuracy: 0.7669\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 166us/sample - loss: 0.4667 - accuracy: 0.7721\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 167us/sample - loss: 0.4768 - accuracy: 0.7617\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 121us/sample - loss: 0.4666 - accuracy: 0.7669\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.4447 - accuracy: 0.79 - 0s 137us/sample - loss: 0.4696 - accuracy: 0.7773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x257af4be518>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "768/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 102us/sample - loss: 0.4552 - accuracy: 0.7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.17\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make probability predictions with the model\n",
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# round predictions \n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "\n",
    "rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions with the model\n",
    "newpredictions = model.predict_classes(newdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(r'C:\\Users\\saravana.ayyappa\\Desktop\\Intro-to-Machine-Learning-master\\Multi Layer perceptron - Keras\\titanic_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[[ 'Pclass', 'Sex', 'Age', 'SibSp','Parch', 'Fare', 'Embarked']]\n",
    "x = pd.get_dummies(x)\n",
    "y = data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model =Sequential()\n",
    "model.add(Dense(12, input_dim=10, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 891 samples\n",
      "Epoch 1/150\n",
      "891/891 [==============================] - 0s 222us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 2/150\n",
      "891/891 [==============================] - 0s 120us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 3/150\n",
      "891/891 [==============================] - 0s 117us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 4/150\n",
      "891/891 [==============================] - 0s 135us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 5/150\n",
      "891/891 [==============================] - 0s 132us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 6/150\n",
      "891/891 [==============================] - 0s 141us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 7/150\n",
      "891/891 [==============================] - 0s 134us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 8/150\n",
      "891/891 [==============================] - 0s 131us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 9/150\n",
      "891/891 [==============================] - 0s 172us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 10/150\n",
      "891/891 [==============================] - 0s 170us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 11/150\n",
      "891/891 [==============================] - 0s 205us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 12/150\n",
      "891/891 [==============================] - 0s 160us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 13/150\n",
      "891/891 [==============================] - 0s 159us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 14/150\n",
      "891/891 [==============================] - 0s 167us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 15/150\n",
      "891/891 [==============================] - 0s 168us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 16/150\n",
      "891/891 [==============================] - 0s 160us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 17/150\n",
      "891/891 [==============================] - 0s 139us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 18/150\n",
      "891/891 [==============================] - 0s 142us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 19/150\n",
      "891/891 [==============================] - 0s 148us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 20/150\n",
      "891/891 [==============================] - 0s 113us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 21/150\n",
      "891/891 [==============================] - 0s 132us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 22/150\n",
      "891/891 [==============================] - 0s 124us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 23/150\n",
      "891/891 [==============================] - 0s 144us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 24/150\n",
      "891/891 [==============================] - 0s 159us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 25/150\n",
      "891/891 [==============================] - 0s 151us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 26/150\n",
      "891/891 [==============================] - 0s 145us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 27/150\n",
      "891/891 [==============================] - 0s 155us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 28/150\n",
      "891/891 [==============================] - 0s 149us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 29/150\n",
      "891/891 [==============================] - 0s 187us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 30/150\n",
      "891/891 [==============================] - 0s 151us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 31/150\n",
      "891/891 [==============================] - 0s 160us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 32/150\n",
      "891/891 [==============================] - 0s 118us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 33/150\n",
      "891/891 [==============================] - 0s 127us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 34/150\n",
      "891/891 [==============================] - 0s 132us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 35/150\n",
      "891/891 [==============================] - 0s 119us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 36/150\n",
      "891/891 [==============================] - 0s 151us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 37/150\n",
      "891/891 [==============================] - 0s 137us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 38/150\n",
      "891/891 [==============================] - 0s 159us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 39/150\n",
      "891/891 [==============================] - 0s 161us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 40/150\n",
      "891/891 [==============================] - 0s 203us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 41/150\n",
      "891/891 [==============================] - 0s 175us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 42/150\n",
      "891/891 [==============================] - 0s 151us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 43/150\n",
      "891/891 [==============================] - 0s 136us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 44/150\n",
      "891/891 [==============================] - 0s 137us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 45/150\n",
      "891/891 [==============================] - 0s 111us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 46/150\n",
      "891/891 [==============================] - 0s 106us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 47/150\n",
      "891/891 [==============================] - 0s 149us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 48/150\n",
      "891/891 [==============================] - 0s 140us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 49/150\n",
      "891/891 [==============================] - 0s 113us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 50/150\n",
      "891/891 [==============================] - 0s 122us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 51/150\n",
      "891/891 [==============================] - 0s 142us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 52/150\n",
      "891/891 [==============================] - 0s 149us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 53/150\n",
      "891/891 [==============================] - 0s 112us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 54/150\n",
      "891/891 [==============================] - 0s 134us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 55/150\n",
      "891/891 [==============================] - 0s 118us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 56/150\n",
      "891/891 [==============================] - 0s 146us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 57/150\n",
      "891/891 [==============================] - 0s 136us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 58/150\n",
      "891/891 [==============================] - 0s 121us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 59/150\n",
      "891/891 [==============================] - 0s 111us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 60/150\n",
      "891/891 [==============================] - 0s 116us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 61/150\n",
      "891/891 [==============================] - 0s 126us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 62/150\n",
      "891/891 [==============================] - 0s 109us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 63/150\n",
      "891/891 [==============================] - 0s 127us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 64/150\n",
      "891/891 [==============================] - 0s 114us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 65/150\n",
      "891/891 [==============================] - 0s 128us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 66/150\n",
      "891/891 [==============================] - 0s 104us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 67/150\n",
      "891/891 [==============================] - 0s 110us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 68/150\n",
      "891/891 [==============================] - 0s 121us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 69/150\n",
      "891/891 [==============================] - 0s 135us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 70/150\n",
      "891/891 [==============================] - 0s 111us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 71/150\n",
      "891/891 [==============================] - 0s 116us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 72/150\n",
      "891/891 [==============================] - 0s 119us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 73/150\n",
      "891/891 [==============================] - 0s 112us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 74/150\n",
      "891/891 [==============================] - 0s 116us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 75/150\n",
      "891/891 [==============================] - 0s 122us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 76/150\n",
      "891/891 [==============================] - 0s 133us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 77/150\n",
      "891/891 [==============================] - 0s 105us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 113us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 79/150\n",
      "891/891 [==============================] - 0s 101us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 80/150\n",
      "891/891 [==============================] - 0s 116us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 81/150\n",
      "891/891 [==============================] - 0s 97us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 82/150\n",
      "891/891 [==============================] - 0s 134us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 83/150\n",
      "891/891 [==============================] - 0s 97us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 84/150\n",
      "891/891 [==============================] - 0s 103us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 85/150\n",
      "891/891 [==============================] - 0s 130us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 86/150\n",
      "891/891 [==============================] - 0s 126us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 87/150\n",
      "891/891 [==============================] - 0s 121us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 88/150\n",
      "891/891 [==============================] - 0s 123us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 89/150\n",
      "891/891 [==============================] - 0s 123us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 90/150\n",
      "891/891 [==============================] - 0s 116us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 91/150\n",
      "891/891 [==============================] - 0s 105us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 92/150\n",
      "891/891 [==============================] - 0s 113us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 93/150\n",
      "891/891 [==============================] - 0s 116us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 94/150\n",
      "891/891 [==============================] - 0s 109us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 95/150\n",
      "891/891 [==============================] - 0s 107us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 96/150\n",
      "891/891 [==============================] - 0s 117us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 97/150\n",
      "891/891 [==============================] - 0s 102us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 98/150\n",
      "891/891 [==============================] - 0s 126us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 99/150\n",
      "891/891 [==============================] - 0s 94us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 100/150\n",
      "891/891 [==============================] - 0s 111us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 101/150\n",
      "891/891 [==============================] - 0s 131us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 102/150\n",
      "891/891 [==============================] - 0s 108us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 103/150\n",
      "891/891 [==============================] - 0s 125us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 104/150\n",
      "891/891 [==============================] - 0s 99us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 105/150\n",
      "891/891 [==============================] - 0s 108us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 106/150\n",
      "891/891 [==============================] - 0s 127us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 107/150\n",
      "891/891 [==============================] - 0s 116us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 108/150\n",
      "891/891 [==============================] - 0s 121us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 109/150\n",
      "891/891 [==============================] - 0s 103us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 110/150\n",
      "891/891 [==============================] - 0s 121us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 111/150\n",
      "891/891 [==============================] - 0s 97us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 112/150\n",
      "891/891 [==============================] - 0s 118us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 113/150\n",
      "891/891 [==============================] - 0s 110us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 114/150\n",
      "891/891 [==============================] - 0s 145us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 115/150\n",
      "891/891 [==============================] - 0s 154us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 116/150\n",
      "891/891 [==============================] - 0s 107us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 117/150\n",
      "891/891 [==============================] - 0s 160us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 118/150\n",
      "891/891 [==============================] - 0s 112us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 119/150\n",
      "891/891 [==============================] - 0s 155us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 120/150\n",
      "891/891 [==============================] - 0s 143us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 121/150\n",
      "891/891 [==============================] - 0s 127us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 122/150\n",
      "891/891 [==============================] - 0s 148us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 123/150\n",
      "891/891 [==============================] - 0s 131us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 124/150\n",
      "891/891 [==============================] - 0s 134us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 125/150\n",
      "891/891 [==============================] - 0s 145us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 126/150\n",
      "891/891 [==============================] - 0s 154us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 127/150\n",
      "891/891 [==============================] - 0s 154us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 128/150\n",
      "891/891 [==============================] - 0s 150us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 129/150\n",
      "891/891 [==============================] - 0s 149us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 130/150\n",
      "891/891 [==============================] - 0s 157us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 131/150\n",
      "891/891 [==============================] - 0s 142us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 132/150\n",
      "891/891 [==============================] - 0s 149us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 133/150\n",
      "891/891 [==============================] - 0s 143us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 134/150\n",
      "891/891 [==============================] - 0s 180us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 135/150\n",
      "891/891 [==============================] - 0s 150us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 136/150\n",
      "891/891 [==============================] - 0s 127us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 137/150\n",
      "891/891 [==============================] - 0s 139us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 138/150\n",
      "891/891 [==============================] - 0s 153us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 139/150\n",
      "891/891 [==============================] - 0s 173us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 140/150\n",
      "891/891 [==============================] - 0s 125us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 141/150\n",
      "891/891 [==============================] - 0s 147us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 142/150\n",
      "891/891 [==============================] - 0s 145us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 143/150\n",
      "891/891 [==============================] - 0s 159us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 144/150\n",
      "891/891 [==============================] - 0s 141us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 145/150\n",
      "891/891 [==============================] - 0s 126us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 146/150\n",
      "891/891 [==============================] - 0s 111us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 147/150\n",
      "891/891 [==============================] - 0s 103us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 148/150\n",
      "891/891 [==============================] - 0s 127us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 149/150\n",
      "891/891 [==============================] - 0s 144us/sample - loss: nan - accuracy: 0.6162\n",
      "Epoch 150/150\n",
      "891/891 [==============================] - 0s 108us/sample - loss: nan - accuracy: 0.6162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x257b2233e10>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(x, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "891/891 [==============================] - 0s 44us/sample - loss: nan - accuracy: 0.6162\n",
      "Accuracy: 61.62\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(x, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = x[700:]\n",
    "model.predict(testdata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
